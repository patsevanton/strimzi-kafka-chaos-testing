replicaCount: 50

image:
  repository: docker.io/antonpatsev/strimzi-kafka-chaos-testing
  pullPolicy: IfNotPresent
  tag: "0.2.12"

imagePullSecrets: []
nameOverride: ""
fullnameOverride: ""

serviceAccount:
  create: true
  annotations: {}
  name: ""

podAnnotations: {}

podSecurityContext: {}
  # fsGroup: 2000

securityContext: {}
  # capabilities:
  #   drop:
  #   - ALL
  # readOnlyRootFilesystem: true
  # runAsNonRoot: true
  # runAsUser: 1000

# Формула ресурсов: 10 msg/s × Avro encode + Redis → limits выше requests.
resources:
  limits:
    cpu: 2000m    # 2 × 1000m на под (encode + сеть)
    memory: 1Gi   # 256Mi base + Avro buffers + metrics ≈ 1Gi
  requests:
    cpu: 500m     # 0.5 ядра гарантировано на под
    memory: 256Mi # база для одного producer-пода

nodeSelector: {}

tolerations: []

affinity: {}

autoscaling:
  enabled: false
  minReplicas: 10   # формула: базовый пул (нагрузка / целевой throughput на под)
  maxReplicas: 100  # minReplicas × 10 — запас при autoscaling
  targetCPUUtilizationPercentage: 80
  targetMemoryUtilizationPercentage: 80

# Конфигурация Kafka (SASL SCRAM-SHA-512)
kafka:
  # Сервис Strimzi bootstrap (работает между namespace через DNS)
  brokers: "kafka-cluster-kafka-bootstrap.kafka-cluster.svc.cluster.local:9092"
  topic: "test-topic"
  # producerBatchSize × producerBatchTimeoutMs: батч до 50 сообщений или 50 ms — что раньше.
  producerBatchSize: 50      # формула: throughput × латентность (например 10 msg/s × 5 s)
  producerBatchTimeoutMs: 50 # макс ожидание батча (ms) перед отправкой
  # producerIntervalMs: интервал между сообщениями (ms). 100 = 10 msg/s на под.
  producerIntervalMs: 100    # уменьшить для большей нагрузки (50→20 msg/s, 20→50 msg/s)
  # messagePayloadBytes: дополнять payload до N байт (0 = без padding). Увеличивает MB/s.
  messagePayloadBytes: 4096
  # Учётные данные KafkaUser — только через Secret (kind: Secret). Strimzi создаёт Secret myuser с ключом password.
  username: "myuser"
  # Имя Secret в том же namespace, из которого берётся пароль (обязательно для SASL).
  existingSecret: "myuser"
  existingSecretPasswordKey: "password"

# Конфигурация Schema Registry
schemaRegistry:
  # Сервис развёрнут в namespace "schema-registry" в этом репозитории
  url: "http://schema-registry.schema-registry:8081"

# Redis для верификации доставки (хеш тела сообщения). Producer пишет в Redis после отправки в Kafka.
redis:
  addr: "redis.redis.svc.cluster.local:6379"
  password: ""
  # keyPrefix: "kafka-msg:"
  sloSeconds: 120  # формула: допустимая задержка доставки (сек); 120 = 2 мин

# Конфигурация проверки здоровья
health:
  port: 8080
  livenessProbe:
    initialDelaySeconds: 10
    periodSeconds: 10
    timeoutSeconds: 5
    failureThreshold: 3
  readinessProbe:
    initialDelaySeconds: 15
    periodSeconds: 10
    timeoutSeconds: 5
    failureThreshold: 3
